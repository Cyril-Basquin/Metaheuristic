{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.problem import ZDT1\n",
    "problem = ZDT1()\n",
    "\n",
    "from jmetal.problem import ZDT4\n",
    "problem = ZDT4()\n",
    "\n",
    "from jmetal.problem import LZ09_F2\n",
    "problem = LZ09_F2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Multi-objective algorithms\n",
    "\n",
    "## A/ Evolutionary algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) GDE3 : Generalized Differential Evolution (3)\n",
    "https://www.iitk.ac.in/kangal/papers/k2005013.pdf\n",
    "\n",
    "**ABSTRACT :** A developed version of Generalized Differential Evolution, GDE3, is proposed. GDE3 is an extension of Differential Evolution (DE) for global optimization with an arbitrary number of objectives and constraints. In the case of a problem with a single objective and without constraints GDE3 falls back to the original DE. GDE3 improves earlier GDE versions in the case of multi-objective problems by giving a better distributed solution. Performance of GDE3 is demonstrated with a set of test problems and the results are compared with other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.gde3 import GDE3\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "max_evaluations = 25000\n",
    "Population_Size = 100\n",
    "cr = 0.5\n",
    "f = 0.5\n",
    "\n",
    "algorithm = GDE3(\n",
    "    problem=problem,\n",
    "    population_size=Population_Size,\n",
    "    cr=cr,\n",
    "    f=f,\n",
    "    termination_criterion=StoppingByEvaluations(max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HypE: An Algorithm for Fast Hypervolume-Based Many-Objective Optimization\n",
    "\n",
    "https://www.mitpressjournals.org/doi/10.1162/EVCO_a_00009\n",
    "\n",
    "**ABSTRACT:** In the field of evolutionary multi-criterion optimization, the hypervolume indicator is the only single set quality measure that is known to be strictly monotonic with regard to Pareto dominance: whenever a Pareto set approximation entirely dominates another one, then the indicator value of the dominant set will also be better. This property is of high interest and relevance for problems involving a large number of objective functions. However, the high computational effort required for hypervolume calculation has so far prevented the full exploitation of this indicator's potential; current hypervolume-based search algorithms are limited to problems with only a few objectives.\n",
    "\n",
    "This paper addresses this issue and proposes a fast search algorithm that uses Monte Carlo simulation to approximate the exact hypervolume values. The main idea is not that the actual indicator values are important, but rather that the rankings of solutions induced by the hypervolume indicator. In detail, we present HypE, a hypervolume estimation algorithm for multi-objective optimization, by which the accuracy of the estimates and the available computing resources can be traded off; thereby, not only do many-objective problems become feasible with hypervolume-based search, but also the runtime can be flexibly adapted. Moreover, we show how the same principle can be used to statistically compare the outcomes of different multi-objective optimizers with respect to the hypervolume—so far, statistical testing has been restricted to scenarios with few objectives. The experimental results indicate that HypE is highly effective for many-objective problems in comparison to existing multi-objective evolutionary algorithms.\n",
    "\n",
    "HypE is available for download at http://www.tik.ee.ethz.ch/sop/download/supplementary/hype/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.hype import HYPE\n",
    "from jmetal.core.solution import FloatSolution\n",
    "from jmetal.operator import SBXCrossover, PolynomialMutation\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "reference_point = FloatSolution([0], [1], problem.number_of_objectives, )\n",
    "reference_point.objectives = [1., 1.]  # Mandatory for HYPE\n",
    "\n",
    "max_evaluations = 25000\n",
    "Population_Size = 100\n",
    "Offspring_Population_Size = 100\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "\n",
    "algorithm = HYPE(\n",
    "    problem=problem,\n",
    "    reference_point=reference_point,\n",
    "    population_size= Population_Size,\n",
    "    offspring_population_size=Offspring_Population_Size,\n",
    "    mutation=PolynomialMutation(probabilit Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    crossover=SBXCrossover(probability= Crossover_Probability, distribution_index=20),\n",
    "    termination_criterion=StoppingByEvaluations(max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) IBEA: Indicator-Based Selection in Multiobjective Search\n",
    "\n",
    "WARNING: NOT SURE THAT IS THE ORIGINAL PAPER\n",
    "https://link.springer.com/chapter/10.1007/978-3-540-30217-9_84\n",
    "\n",
    "**ABSTRACT**: This paper discusses how preference information of the decision maker can in general be integrated into multiobjective search. The main idea is to first define the optimization goal in terms of a binary performance measure (indicator) and then to directly use this measure in the selection process. To this end, we propose a general indicator-based evolutionary algorithm (IBEA) that can be combined with arbitrary indicators. In contrast to existing algorithms, IBEA can be adapted to the preferences of the user and moreover does not require any additional diversity preservation mechanism such as fitness sharing to be used. It is shown on several continuous and discrete benchmark problems that IBEA can substantially improve on the results generated by two popular algorithms, namely NSGA-II and SPEA2, with respect to different performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.ibea import IBEA\n",
    "from jmetal.operator import SBXCrossover, PolynomialMutation\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "max_evaluations = 25000\n",
    "Kappa = 1.0\n",
    "Population_Size = 100\n",
    "Offspring_Population_Size = 100\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "\n",
    "algorithm = IBEA(\n",
    "    problem=problem,\n",
    "    kappa= Kappa,\n",
    "    population_size= Population_Size,\n",
    "    offspring_population_size= Offspring_Population_Size,\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    crossover=SBXCrossover(probability= Crossover_Probability, distribution_index=20),\n",
    "    termination_criterion=StoppingByEvaluations(max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) MOCell: A cellular genetic algorithm for multiobjective optimization\n",
    "\n",
    "https://onlinelibrary.wiley.com/doi/abs/10.1002/int.20358\n",
    "\n",
    "\n",
    "**ABSTRACT:** This paper introduces a new cellular genetic algorithm for solving multiobjective continuous optimization problems. Our approach is characterized by using an external archive to store nondominated solutions and a feedback mechanism in which solutions from this archive randomly replace existing individuals in the population after each iteration. The result is a simple and elitist algorithm called MOCell. Our proposal has been evaluated with both constrained and unconstrained problems and compared against NSGA‐II and SPEA2, two state‐of‐the‐art evolutionary multiobjective optimizers. For the studied benchmark, our experiments indicate that MOCell obtains competitive results in terms of convergence and hypervolume, and it clearly outperforms the other two compared algorithms concerning the diversity of the solutions along the Pareto front. © 2009 Wiley Periodicals, Inc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOCell\n",
    "\n",
    "from jmetal.algorithm.multiobjective.mocell import MOCell\n",
    "from jmetal.operator import SBXCrossover, PolynomialMutation\n",
    "from jmetal.util.archive import CrowdingDistanceArchive\n",
    "from jmetal.util.neighborhood import C9\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "Population_Size = 100\n",
    "Neighborhood_1 = 10\n",
    "Neighborhood_2 = 10\n",
    "Crowding_distance = 100\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "max_evaluations = 25000\n",
    "\n",
    "algorithm = MOCell(\n",
    "    problem=problem,\n",
    "    population_size=Population_Size,\n",
    "    neighborhood=C9(Neighborhood_1 , Neighborhood_2),\n",
    "    archive=CrowdingDistanceArchive(Crowding_distance),\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    crossover=SBXCrossover(probability= Crossover_Probability, distribution_index=20),\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition\n",
    "\n",
    "https://ieeexplore.ieee.org/document/4358754\n",
    "\n",
    "**ABSTRACT :** Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.moead import MOEAD\n",
    "from jmetal.operator import PolynomialMutation, DifferentialEvolutionCrossover\n",
    "from jmetal.util.aggregative_function import Tschebycheff\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "\n",
    "Population_Size = 300\n",
    "cr = 1\n",
    "f = 0.5\n",
    "k = 0.5\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "Neighbor_Size = 20\n",
    "Neighbor_selection_probability = 0.9\n",
    "Max_Number_Of_Replaced_Solutions = 2\n",
    "max_evaluations = 150000\n",
    "\n",
    "\n",
    "algorithm = MOEAD(\n",
    "    problem=problem,\n",
    "    population_size= Population_Size,\n",
    "    crossover=DifferentialEvolutionCrossover(CR=cr, F=f, K=k),\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    aggregative_function=Tschebycheff(dimension=problem.number_of_objectives),\n",
    "    neighbor_size= Neighbor_Size,\n",
    "    neighbourhood_selection_probability= Neighbor_selection_probability,\n",
    "    max_number_of_replaced_solutions= Max_Number_Of_Replaced_Solutions,\n",
    "    weight_files_path='resources/MOEAD_weights',\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")\n",
    "\n",
    "algorithm.run()\n",
    "solutions = algorithm.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) NSGA-II : non dominated sorting genetic algorithm II\n",
    "\n",
    "Warning: Not the original paper\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S1877705811022466\n",
    "\n",
    "**ABSTRACT:** This paper presents an overview on NSGA-II optimization techniques of machining process parameters. There are many multi objective optimization (MoGA) techniques involved in machining process parameters optimization including multi-objective genetic algorithm (MOGA), strength Pareto evolutionary algorithm (SPEA), micro genetic algorithm (Micro-GA), Pareto-archived evolution strategy (PAES), etc. This paper reviews the application of non dominated sorting genetic algorithm II (NSGA-II), classified as one of MoGA techniques, for optimizing process parameters in various machining operations. NSGA-II is a well known, fast sorting and elite multi objective genetic algorithm. Process parameters such as cutting speed, feed rate, rotational speed etc. are the considerable conditions in order to optimize the machining operations in minimizing or maximizing the machining performances. Unlike the single objective optimization technique, NSGA-II simultaneously optimizes each objective without being dominated by any other solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.nsgaii import NSGAII\n",
    "from jmetal.operator import SBXCrossover, PolynomialMutation\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "Population_Size = 100\n",
    "Offspring_Population_Size = 100\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "max_evaluations = 25000\n",
    "\n",
    "algorithm = NSGAII(\n",
    "    problem=problem,\n",
    "    population_size= Population_Size,\n",
    "    offspring_population_size= Offspring_Population_Size,\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    crossover=SBXCrossover(probability= Crossover_Probability, distribution_index=20),\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) SPEA2 : Improed Strength Pareto Evolutionary Algorithm for Multiobjective Optimization\n",
    "\n",
    "https://www.researchgate.net/publication/216301720_SPEA2_Improving_the_Strength_Pareto_Evolutionary_Algorithm_for_Multiobjective_Optimization\n",
    "\n",
    "**ABSTRACT:** The Strength Pareto Evolutionary Algorithm (SPEA) (Zitzler and Thiele 1999)is a relatively recent technique for finding or approximating the Pareto-optimal setfor multiobjective optimization problems.  In different studies (Zitzler and Thiele1999; Zitzler, Deb, and Thiele 2000) SPEA has shown very good performance incomparison to other multiobjective evolutionary algorithms, and therefore it hasbeen a point of reference in various recent investigations, e.g., (Corne, Knowles,and Oates 2000). Furthermore, it has been used in different applications, e.g., (La-hanas, Milickovic, Baltas, and Zamboglou 2001).  In this paper, an improved ver-sion, namely SPEA2, is proposed, which incorporates in contrast to its predecessora fine-grained fitness assignment strategy, a density estimation technique, and anenhanced archive truncation method.  The comparison of SPEA2 with SPEA andtwo other modern elitist methods, PESA and NSGA-II, on different test problemsyields promising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.spea2 import SPEA2\n",
    "from jmetal.operator import SBXCrossover, PolynomialMutation\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "Population_Size = 40\n",
    "Offspring_Population_Size = 40\n",
    "Mutation_Probability = 1.0\n",
    "Crossover_Probability = 1.0\n",
    "max_evaluations = 20000\n",
    "\n",
    "algorithm = SPEA2(\n",
    "    problem=problem,\n",
    "    population_size= Population_Size,\n",
    "    offspring_population_size= Offspring_Population_Size,\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    crossover=SBXCrossover(probability= Crossover_Probability, distribution_index=20),\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) OMOPSO: Optimized Multi-Objective Particle Swarm Optimization\n",
    "\n",
    "https://link.springer.com/chapter/10.1007%2F978-3-540-31880-4_35\n",
    "\n",
    "**ABSTRACT::** In this paper, we propose a new Multi-Objective Particle Swarm Optimizer, which is based on Pareto dominance and the use of a crowding factor to filter out the list of available leaders. We also propose the use of different mutation (or turbulence) operators which act on different subdivisions of the swarm. Finally, the proposed approach also incorporates the ∈-dominance concept to fix the size of the set of final solutions produced by the algorithm. Our approach is compared against five state-of-the-art algorithms, including three PSO-based approaches recently proposed. The results indicate that the proposed approach is highly competitive, being able to approximate the front even in cases where all the other PSO-based approaches fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.omopso import OMOPSO\n",
    "from jmetal.operator import UniformMutation\n",
    "from jmetal.operator.mutation import NonUniformMutation\n",
    "from jmetal.util.archive import CrowdingDistanceArchive\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "swarm_size = 100\n",
    "Epsilon = 0.0075\n",
    "Mutation_Probability = 1.0 / problem.number_of_variables\n",
    "Perturbation = 0.5\n",
    "\n",
    "algorithm = OMOPSO(\n",
    "    problem=problem,\n",
    "    swarm_size=swarm_size,\n",
    "    epsilon= Epsilon,\n",
    "    uniform_mutation=UniformMutation(probability=Mutation_Probability, perturbation= Perturbation),\n",
    "    non_uniform_mutation=NonUniformMutation(Mutation_Probability, perturbation= Perturbation,\n",
    "                                            max_iterations=int(max_evaluations / swarm_size)),\n",
    "    leaders=CrowdingDistanceArchive(100),\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SMPSO: A new PSO-based metaheuristic for multi-objective optimization\n",
    "\n",
    "https://ieeexplore.ieee.org/document/4938830\n",
    "\n",
    "**ABSTRACT:** In this work, we present a new multi-objective particle swarm optimization algorithm (PSO) characterized by the use of a strategy to limit the velocity of the particles. The proposed approach, called Speed-constrained Multi-objective PSO (SMPSO) allows to produce new effective particle positions in those cases in which the velocity becomes too high. Other features of SMPSO include the use of polynomial mutation as a turbulence factor and an external archive to store the non-dominated solutions found during the search. Our proposed approach is compared with respect to five multi-objective metaheuristics representative of the state-of-the-art in the area. For the comparison, two different criteria are adopted: the quality of the resulting approximation sets and the convergence speed to the Pareto front. The experiments carried out indicate that SMPSO obtains remarkable results in terms of both, accuracy and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.algorithm.multiobjective.smpso import SMPSO\n",
    "from jmetal.operator import PolynomialMutation\n",
    "from jmetal.util.archive import CrowdingDistanceArchive\n",
    "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
    "\n",
    "Swarm_Size = 100\n",
    "Mutation_Probability = 1.0\n",
    "Crowding_Distance = 100\n",
    "max_evaluations = 25000\n",
    "\n",
    "algorithm = SMPSO(\n",
    "    problem=problem,\n",
    "    swarm_size= Swarm_Size,\n",
    "    mutation=PolynomialMutation(probability= Mutation_Probability / problem.number_of_variables, distribution_index=20),\n",
    "    leaders=CrowdingDistanceArchive(Crowding_Distance),\n",
    "    termination_criterion=StoppingByEvaluations(max=max_evaluations)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algorithm and Get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.run()\n",
    "solutions = algorithm.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Pareto Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.lab.visualization.plotting import Plot\n",
    "from jmetal.util.solution import get_non_dominated_solutions\n",
    "\n",
    "front = get_non_dominated_solutions(solutions)\n",
    "\n",
    "plot_front = Plot(plot_title='Pareto front approximation', axis_labels=['x', 'y'])\n",
    "plot_front.plot(front, label='GDE3-ZDT1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
